{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HHrasHZzq60T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db484a0b-4774-47f0-b6ac-107a0a8a8d29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Importing NFL stats dataset\n",
        "file_path = '/content/drive/My Drive/Sports Modeling/nfl/imputed_data.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "Thf7Bn85MN1D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the count of null values in each column\n",
        "null_counts = data.isnull().sum()\n",
        "\n",
        "# Filter the columns with null values\n",
        "null_counts = null_counts[null_counts > 0]\n",
        "\n",
        "# Display the columns with their respective null value counts\n",
        "print(null_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlzp4d2f3THD",
        "outputId": "bd9a1be4-0eb8-489a-ae34-b24ca804e6e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column 'result' with default value 0 (for draws)\n",
        "data['result'] = 0\n",
        "\n",
        "# Set the result to 1 where home team wins\n",
        "data.loc[data['home_points'] > data['away_points'], 'result'] = 1\n",
        "\n",
        "# Set the result to -1 where away team wins\n",
        "data.loc[data['home_points'] < data['away_points'], 'result'] = -1"
      ],
      "metadata": {
        "id": "5KkQ_a2N4dav"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['result'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOi-vZG6PsOZ",
        "outputId": "b9abec20-d0b4-4940-b731-ef7f1a8e5f02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result\n",
            " 1    3404\n",
            "-1    2635\n",
            " 0      14\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display columns that are not numerical\n",
        "non_numerical_data = data.select_dtypes(exclude=['int64', 'float64'])\n",
        "\n",
        "# Display the first few rows of these non-numerical columns\n",
        "print(non_numerical_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUHhvEzH4dYj",
        "outputId": "5a6396b5-caf3-4acd-fa9b-68b626ec04d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             venue_name       venue_city venue_surface venue_roof_type  \\\n",
            "0  Three Rivers Stadium       Pittsburgh    artificial         outdoor   \n",
            "1  RingCentral Coliseum          Oakland          turf         outdoor   \n",
            "2          Georgia Dome          Atlanta    artificial            dome   \n",
            "3        Giants Stadium  East Rutherford    artificial         outdoor   \n",
            "4     Caesars Superdome      New Orleans    artificial            dome   \n",
            "\n",
            "  home_name  away_name home_possession_time away_possession_time  \n",
            "0  Steelers     Ravens                24:53                35:07  \n",
            "1   Raiders   Chargers                31:30                28:30  \n",
            "2   Falcons      49ers                31:39                28:21  \n",
            "3    Giants  Cardinals                31:30                28:30  \n",
            "4    Saints      Lions                29:11                30:49  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['venue_name', 'venue_city'], axis=1)  # Dropping Unnecessary Columns"
      ],
      "metadata": {
        "id": "DDOXfEUr4dWX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert possession time from format 'MM:SS' to total seconds\n",
        "data['home_possession_time_seconds'] = data['home_possession_time'].apply(lambda x: int(x.split(':')[0]) * 60 + int(x.split(':')[1]))\n",
        "data['away_possession_time_seconds'] = data['away_possession_time'].apply(lambda x: int(x.split(':')[0]) * 60 + int(x.split(':')[1]))"
      ],
      "metadata": {
        "id": "8B8Xxc1V4dUP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the original time columns\n",
        "data = data.drop(['home_possession_time', 'away_possession_time'], axis=1)\n",
        "\n",
        "# Now check for non-numerical columns again\n",
        "non_numerical_data = data.select_dtypes(exclude=['int64', 'float64'])\n",
        "print(non_numerical_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plVTwKxS61R2",
        "outputId": "30f2caac-6dd8-4274-e4ca-8675b587311f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  venue_surface venue_roof_type home_name  away_name\n",
            "0    artificial         outdoor  Steelers     Ravens\n",
            "1          turf         outdoor   Raiders   Chargers\n",
            "2    artificial            dome   Falcons      49ers\n",
            "3    artificial         outdoor    Giants  Cardinals\n",
            "4    artificial            dome    Saints      Lions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply Label Encoding to each categorical column\n",
        "data['venue_surface_encoded'] = label_encoder.fit_transform(data['venue_surface'])\n",
        "data['venue_roof_type_encoded'] = label_encoder.fit_transform(data['venue_roof_type'])\n",
        "data['home_name_encoded'] = label_encoder.fit_transform(data['home_name'])\n",
        "data['away_name_encoded'] = label_encoder.fit_transform(data['away_name'])\n",
        "\n",
        "# Drop the original columns if you no longer need them\n",
        "data = data.drop(['venue_surface', 'venue_roof_type', 'home_name', 'away_name'], axis=1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "D6ML2lwX61Pp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CoDE5PE61Nv",
        "outputId": "a14fb185-b023-451c-8bda-c0dfc50e47bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['attendance', 'quarter', 'season_year', 'week_sequence', 'week_title', 'venue_capacity', 'home_used_timeouts', 'home_remaining_timeouts', 'home_points', 'away_used_timeouts', 'away_remaining_timeouts', 'away_points', 'home_avg_gain', 'home_safeties', 'home_turnovers', 'home_play_count', 'home_rush_plays', 'home_total_yards', 'home_fumbles', 'home_lost_fumbles', 'home_penalties', 'home_penalty_yards', 'home_return_yards', 'home_rushing_totals_avg_yards', 'home_rushing_totals_attempts', 'home_rushing_totals_touchdowns', 'home_rushing_totals_tlost', 'home_rushing_totals_tlost_yards', 'home_rushing_totals_yards', 'home_rushing_totals_longest', 'home_rushing_totals_longest_touchdown', 'home_rushing_totals_redzone_attempts', 'home_receiving_totals_targets', 'home_receiving_totals_receptions', 'home_receiving_totals_avg_yards', 'home_receiving_totals_yards', 'home_receiving_totals_touchdowns', 'home_receiving_totals_yards_after_catch', 'home_receiving_totals_longest', 'home_receiving_totals_longest_touchdown', 'home_receiving_totals_redzone_targets', 'home_receiving_totals_air_yards', 'home_punts_totals_attempts', 'home_punts_totals_yards', 'home_punts_totals_net_yards', 'home_punts_totals_blocked', 'home_punts_totals_touchbacks', 'home_punts_totals_inside_20', 'home_punts_totals_return_yards', 'home_punts_totals_avg_net_yards', 'home_punts_totals_avg_yards', 'home_punts_totals_longest', 'home_punt_returns_totals_avg_yards', 'home_punt_returns_totals_yards', 'home_punt_returns_totals_longest', 'home_punt_returns_totals_touchdowns', 'home_punt_returns_totals_longest_touchdown', 'home_punt_returns_totals_faircatches', 'home_punt_returns_totals_number', 'home_penalties_totals_penalties', 'home_penalties_totals_yards', 'home_passing_totals_attempts', 'home_passing_totals_completions', 'home_passing_totals_cmp_pct', 'home_passing_totals_interceptions', 'home_passing_totals_sack_yards', 'home_passing_totals_rating', 'home_passing_totals_touchdowns', 'home_passing_totals_avg_yards', 'home_passing_totals_sacks', 'home_passing_totals_longest', 'home_passing_totals_longest_touchdown', 'home_passing_totals_air_yards', 'home_passing_totals_redzone_attempts', 'home_passing_totals_net_yards', 'home_passing_totals_yards', 'home_misc_returns_totals_yards', 'home_misc_returns_totals_touchdowns', 'home_misc_returns_totals_blk_fg_touchdowns', 'home_misc_returns_totals_blk_punt_touchdowns', 'home_misc_returns_totals_fg_return_touchdowns', 'home_misc_returns_totals_ez_rec_touchdowns', 'home_misc_returns_totals_number', 'home_kickoffs_totals_endzone', 'home_kickoffs_totals_inside_20', 'home_kickoffs_totals_return_yards', 'home_kickoffs_totals_touchbacks', 'home_kickoffs_totals_yards', 'home_kickoffs_totals_out_of_bounds', 'home_kickoffs_totals_number', 'home_kickoffs_totals_total_endzone', 'home_kick_returns_totals_avg_yards', 'home_kick_returns_totals_yards', 'home_kick_returns_totals_longest', 'home_kick_returns_totals_touchdowns', 'home_kick_returns_totals_longest_touchdown', 'home_kick_returns_totals_faircatches', 'home_kick_returns_totals_number', 'home_int_returns_totals_avg_yards', 'home_int_returns_totals_yards', 'home_int_returns_totals_touchdowns', 'home_int_returns_totals_number', 'home_fumbles_totals_fumbles', 'home_fumbles_totals_lost_fumbles', 'home_fumbles_totals_own_rec', 'home_fumbles_totals_own_rec_yards', 'home_fumbles_totals_opp_rec', 'home_fumbles_totals_opp_rec_yards', 'home_fumbles_totals_out_of_bounds', 'home_fumbles_totals_forced_fumbles', 'home_fumbles_totals_own_rec_tds', 'home_fumbles_totals_opp_rec_tds', 'home_fumbles_totals_ez_rec_tds', 'home_field_goals_totals_attempts', 'home_field_goals_totals_made', 'home_field_goals_totals_blocked', 'home_field_goals_totals_yards', 'home_field_goals_totals_avg_yards', 'home_field_goals_totals_longest', 'home_field_goals_totals_net_attempts', 'home_field_goals_totals_pct', 'home_defense_totals_tackles', 'home_defense_totals_assists', 'home_defense_totals_combined', 'home_defense_totals_sacks', 'home_defense_totals_sack_yards', 'home_defense_totals_interceptions', 'home_defense_totals_passes_defended', 'home_defense_totals_forced_fumbles', 'home_defense_totals_fumble_recoveries', 'home_defense_totals_qb_hits', 'home_defense_totals_tloss', 'home_defense_totals_tloss_yards', 'home_defense_totals_safeties', 'home_defense_totals_sp_tackles', 'home_defense_totals_sp_assists', 'home_defense_totals_sp_forced_fumbles', 'home_defense_totals_sp_fumble_recoveries', 'home_defense_totals_sp_blocks', 'home_defense_totals_misc_tackles', 'home_defense_totals_misc_assists', 'home_defense_totals_misc_forced_fumbles', 'home_defense_totals_misc_fumble_recoveries', 'home_extra_points_kicks_totals_attempts', 'home_extra_points_kicks_totals_blocked', 'home_extra_points_kicks_totals_made', 'home_extra_points_kicks_totals_pct', 'home_extra_points_conversions_totals_pass_attempts', 'home_extra_points_conversions_totals_pass_successes', 'home_extra_points_conversions_totals_rush_attempts', 'home_extra_points_conversions_totals_rush_successes', 'home_extra_points_conversions_totals_defense_attempts', 'home_extra_points_conversions_totals_defense_successes', 'home_extra_points_conversions_totals_turnover_successes', 'home_first_downs_pass', 'home_first_downs_penalty', 'home_first_downs_rush', 'home_first_downs_total', 'home_interceptions_return_yards', 'home_interceptions_returned', 'home_interceptions_number', 'home_touchdowns_pass', 'home_touchdowns_rush', 'home_touchdowns_total_return', 'home_touchdowns_total', 'home_touchdowns_fumble_return', 'home_touchdowns_int_return', 'home_touchdowns_kick_return', 'home_touchdowns_punt_return', 'home_touchdowns_other', 'home_efficiency_goaltogo_attempts', 'home_efficiency_goaltogo_successes', 'home_efficiency_goaltogo_pct', 'home_efficiency_redzone_attempts', 'home_efficiency_redzone_successes', 'home_efficiency_redzone_pct', 'home_efficiency_thirddown_attempts', 'home_efficiency_thirddown_successes', 'home_efficiency_thirddown_pct', 'home_efficiency_fourthdown_attempts', 'home_efficiency_fourthdown_successes', 'home_efficiency_fourthdown_pct', 'away_avg_gain', 'away_safeties', 'away_turnovers', 'away_play_count', 'away_rush_plays', 'away_total_yards', 'away_fumbles', 'away_lost_fumbles', 'away_penalties', 'away_penalty_yards', 'away_return_yards', 'away_rushing_totals_avg_yards', 'away_rushing_totals_attempts', 'away_rushing_totals_touchdowns', 'away_rushing_totals_tlost', 'away_rushing_totals_tlost_yards', 'away_rushing_totals_yards', 'away_rushing_totals_longest', 'away_rushing_totals_longest_touchdown', 'away_rushing_totals_redzone_attempts', 'away_receiving_totals_targets', 'away_receiving_totals_receptions', 'away_receiving_totals_avg_yards', 'away_receiving_totals_yards', 'away_receiving_totals_touchdowns', 'away_receiving_totals_yards_after_catch', 'away_receiving_totals_longest', 'away_receiving_totals_longest_touchdown', 'away_receiving_totals_redzone_targets', 'away_receiving_totals_air_yards', 'away_punts_totals_attempts', 'away_punts_totals_yards', 'away_punts_totals_net_yards', 'away_punts_totals_blocked', 'away_punts_totals_touchbacks', 'away_punts_totals_inside_20', 'away_punts_totals_return_yards', 'away_punts_totals_avg_net_yards', 'away_punts_totals_avg_yards', 'away_punts_totals_longest', 'away_punt_returns_totals_avg_yards', 'away_punt_returns_totals_yards', 'away_punt_returns_totals_longest', 'away_punt_returns_totals_touchdowns', 'away_punt_returns_totals_longest_touchdown', 'away_punt_returns_totals_faircatches', 'away_punt_returns_totals_number', 'away_penalties_totals_penalties', 'away_penalties_totals_yards', 'away_passing_totals_attempts', 'away_passing_totals_completions', 'away_passing_totals_cmp_pct', 'away_passing_totals_interceptions', 'away_passing_totals_sack_yards', 'away_passing_totals_rating', 'away_passing_totals_touchdowns', 'away_passing_totals_avg_yards', 'away_passing_totals_sacks', 'away_passing_totals_longest', 'away_passing_totals_longest_touchdown', 'away_passing_totals_air_yards', 'away_passing_totals_redzone_attempts', 'away_passing_totals_net_yards', 'away_passing_totals_yards', 'away_misc_returns_totals_yards', 'away_misc_returns_totals_touchdowns', 'away_misc_returns_totals_blk_fg_touchdowns', 'away_misc_returns_totals_blk_punt_touchdowns', 'away_misc_returns_totals_fg_return_touchdowns', 'away_misc_returns_totals_ez_rec_touchdowns', 'away_misc_returns_totals_number', 'away_kickoffs_totals_endzone', 'away_kickoffs_totals_inside_20', 'away_kickoffs_totals_return_yards', 'away_kickoffs_totals_touchbacks', 'away_kickoffs_totals_yards', 'away_kickoffs_totals_out_of_bounds', 'away_kickoffs_totals_number', 'away_kickoffs_totals_total_endzone', 'away_kick_returns_totals_avg_yards', 'away_kick_returns_totals_yards', 'away_kick_returns_totals_longest', 'away_kick_returns_totals_touchdowns', 'away_kick_returns_totals_longest_touchdown', 'away_kick_returns_totals_faircatches', 'away_kick_returns_totals_number', 'away_int_returns_totals_avg_yards', 'away_int_returns_totals_yards', 'away_int_returns_totals_touchdowns', 'away_int_returns_totals_number', 'away_fumbles_totals_fumbles', 'away_fumbles_totals_lost_fumbles', 'away_fumbles_totals_own_rec', 'away_fumbles_totals_own_rec_yards', 'away_fumbles_totals_opp_rec', 'away_fumbles_totals_opp_rec_yards', 'away_fumbles_totals_out_of_bounds', 'away_fumbles_totals_forced_fumbles', 'away_fumbles_totals_own_rec_tds', 'away_fumbles_totals_opp_rec_tds', 'away_fumbles_totals_ez_rec_tds', 'away_field_goals_totals_attempts', 'away_field_goals_totals_made', 'away_field_goals_totals_blocked', 'away_field_goals_totals_yards', 'away_field_goals_totals_avg_yards', 'away_field_goals_totals_longest', 'away_field_goals_totals_net_attempts', 'away_field_goals_totals_pct', 'away_defense_totals_tackles', 'away_defense_totals_assists', 'away_defense_totals_combined', 'away_defense_totals_sacks', 'away_defense_totals_sack_yards', 'away_defense_totals_interceptions', 'away_defense_totals_passes_defended', 'away_defense_totals_forced_fumbles', 'away_defense_totals_fumble_recoveries', 'away_defense_totals_qb_hits', 'away_defense_totals_tloss', 'away_defense_totals_tloss_yards', 'away_defense_totals_safeties', 'away_defense_totals_sp_tackles', 'away_defense_totals_sp_assists', 'away_defense_totals_sp_forced_fumbles', 'away_defense_totals_sp_fumble_recoveries', 'away_defense_totals_sp_blocks', 'away_defense_totals_misc_tackles', 'away_defense_totals_misc_assists', 'away_defense_totals_misc_forced_fumbles', 'away_defense_totals_misc_fumble_recoveries', 'away_extra_points_kicks_totals_attempts', 'away_extra_points_kicks_totals_blocked', 'away_extra_points_kicks_totals_made', 'away_extra_points_kicks_totals_pct', 'away_extra_points_conversions_totals_pass_attempts', 'away_extra_points_conversions_totals_pass_successes', 'away_extra_points_conversions_totals_rush_attempts', 'away_extra_points_conversions_totals_rush_successes', 'away_extra_points_conversions_totals_defense_attempts', 'away_extra_points_conversions_totals_defense_successes', 'away_extra_points_conversions_totals_turnover_successes', 'away_first_downs_pass', 'away_first_downs_penalty', 'away_first_downs_rush', 'away_first_downs_total', 'away_interceptions_return_yards', 'away_interceptions_returned', 'away_interceptions_number', 'away_touchdowns_pass', 'away_touchdowns_rush', 'away_touchdowns_total_return', 'away_touchdowns_total', 'away_touchdowns_fumble_return', 'away_touchdowns_int_return', 'away_touchdowns_kick_return', 'away_touchdowns_punt_return', 'away_touchdowns_other', 'away_efficiency_goaltogo_attempts', 'away_efficiency_goaltogo_successes', 'away_efficiency_goaltogo_pct', 'away_efficiency_redzone_attempts', 'away_efficiency_redzone_successes', 'away_efficiency_redzone_pct', 'away_efficiency_thirddown_attempts', 'away_efficiency_thirddown_successes', 'away_efficiency_thirddown_pct', 'away_efficiency_fourthdown_attempts', 'away_efficiency_fourthdown_successes', 'away_efficiency_fourthdown_pct', 'venue_location_lat', 'venue_location_lng', 'home_int_returns_totals_longest', 'home_int_returns_totals_longest_touchdown', 'away_kickoffs_totals_onside_attempts', 'away_kickoffs_totals_onside_successes', 'away_kickoffs_totals_squib_kicks', 'away_int_returns_totals_longest', 'away_int_returns_totals_longest_touchdown', 'away_defense_totals_def_targets', 'away_defense_totals_def_comps', 'away_defense_totals_blitzes', 'away_defense_totals_hurries', 'away_defense_totals_knockdowns', 'away_defense_totals_missed_tackles', 'home_kickoffs_totals_onside_attempts', 'home_kickoffs_totals_onside_successes', 'home_kickoffs_totals_squib_kicks', 'home_defense_totals_def_targets', 'home_defense_totals_def_comps', 'home_defense_totals_blitzes', 'home_defense_totals_hurries', 'home_defense_totals_knockdowns', 'home_defense_totals_missed_tackles', 'home_rushing_totals_broken_tackles', 'home_rushing_totals_kneel_downs', 'home_rushing_totals_scrambles', 'home_rushing_totals_yards_after_contact', 'home_receiving_totals_broken_tackles', 'home_receiving_totals_dropped_passes', 'home_receiving_totals_catchable_passes', 'home_receiving_totals_yards_after_contact', 'home_passing_totals_throw_aways', 'home_passing_totals_defended_passes', 'home_passing_totals_dropped_passes', 'home_passing_totals_spikes', 'home_passing_totals_blitzes', 'home_passing_totals_hurries', 'home_passing_totals_knockdowns', 'away_rushing_totals_broken_tackles', 'away_rushing_totals_kneel_downs', 'away_rushing_totals_scrambles', 'away_rushing_totals_yards_after_contact', 'away_receiving_totals_broken_tackles', 'away_receiving_totals_dropped_passes', 'away_receiving_totals_catchable_passes', 'away_receiving_totals_yards_after_contact', 'away_passing_totals_throw_aways', 'away_passing_totals_defended_passes', 'away_passing_totals_dropped_passes', 'away_passing_totals_spikes', 'away_passing_totals_blitzes', 'away_passing_totals_hurries', 'away_passing_totals_knockdowns', 'home_passing_totals_pocket_time', 'home_punts_totals_hang_time', 'home_punts_totals_avg_hang_time', 'away_punts_totals_hang_time', 'away_punts_totals_avg_hang_time', 'away_passing_totals_pocket_time', 'year', 'month', 'day', 'result', 'home_possession_time_seconds', 'away_possession_time_seconds', 'venue_surface_encoded', 'venue_roof_type_encoded', 'home_name_encoded', 'away_name_encoded']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding most important features\n",
        "\n",
        "\n",
        "> Recursive Feature Elimination (RFE) with a RandomForestClassifier\n",
        "\n"
      ],
      "metadata": {
        "id": "kc3PHs5GadBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Define the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define X by dropping the 'result' column\n",
        "X = data.drop(columns=['result'])\n",
        "\n",
        "# Define y as the 'result' column\n",
        "y = data['result']\n",
        "\n",
        "# Define RFE and select the top 10 features\n",
        "rfe = RFE(estimator=model, n_features_to_select=50, step=1)\n",
        "rfe = rfe.fit(X, y)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X.columns[rfe.support_]\n",
        "print(\"Selected Features:\", selected_features)\n",
        "\n",
        "# Optionally, check the ranking of all features\n",
        "print(\"Feature Ranking:\", rfe.ranking_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bawa1sLW61Lr",
        "outputId": "de45b3fa-0f9a-4275-c705-53b4639b19b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: Index(['home_used_timeouts', 'home_remaining_timeouts', 'home_points',\n",
            "       'away_used_timeouts', 'away_remaining_timeouts', 'away_points',\n",
            "       'home_avg_gain', 'home_rush_plays', 'home_total_yards',\n",
            "       'home_rushing_totals_attempts', 'home_rushing_totals_yards',\n",
            "       'home_receiving_totals_avg_yards', 'home_passing_totals_attempts',\n",
            "       'home_passing_totals_cmp_pct', 'home_passing_totals_rating',\n",
            "       'home_passing_totals_avg_yards', 'home_kickoffs_totals_yards',\n",
            "       'home_kickoffs_totals_number', 'home_kick_returns_totals_yards',\n",
            "       'home_field_goals_totals_yards', 'home_field_goals_totals_avg_yards',\n",
            "       'home_extra_points_kicks_totals_attempts',\n",
            "       'home_extra_points_kicks_totals_made', 'home_touchdowns_total',\n",
            "       'away_turnovers', 'away_rush_plays', 'away_total_yards',\n",
            "       'away_return_yards', 'away_rushing_totals_attempts',\n",
            "       'away_rushing_totals_yards', 'away_receiving_totals_avg_yards',\n",
            "       'away_passing_totals_attempts', 'away_passing_totals_cmp_pct',\n",
            "       'away_passing_totals_sack_yards', 'away_passing_totals_rating',\n",
            "       'away_passing_totals_avg_yards', 'away_passing_totals_net_yards',\n",
            "       'away_kickoffs_totals_yards', 'away_kickoffs_totals_number',\n",
            "       'away_kick_returns_totals_yards', 'away_field_goals_totals_yards',\n",
            "       'away_defense_totals_passes_defended',\n",
            "       'away_extra_points_kicks_totals_attempts',\n",
            "       'away_extra_points_kicks_totals_made', 'away_touchdowns_total',\n",
            "       'away_efficiency_thirddown_pct', 'home_rushing_totals_kneel_downs',\n",
            "       'away_rushing_totals_kneel_downs', 'home_possession_time_seconds',\n",
            "       'away_possession_time_seconds'],\n",
            "      dtype='object')\n",
            "Feature Ranking: [ 18  24 100 165 177 124   1   1   1   1   1   1   1 326  35  46   1   1\n",
            " 187 234 173  12  19 112   1 189 208 158   1  42  79 157  27 142   1   5\n",
            "  83 162  76  85 207  11 204  14  68 342 284 252  98  34  55 136 117 115\n",
            " 105 343 292 251 223 174   9   1 119   1 160  41   1  58   1 166  99  32\n",
            "  72 181  77  81 301 346 363 357 362 368 322 260 274  22 168   1 310   1\n",
            "   2  47   1 106 340 306 359  13 182 130 293 190 198 242 268 224 226 240\n",
            " 307 257 360 314 361 113  31 286   1   1  40 171 183  56  96  21 145   7\n",
            " 120  38 236 255  80 191 156 327 169 221 299 285 305 209 344 333 279   1\n",
            " 350   1 200 289 311 320 348 356 365 367 161 222 123  53 111 163 126 109\n",
            " 176 272   1 338 302 336 329 328 214 203 225  30  15 118 159 184  45  67\n",
            " 270 283  10 313   1  84   1   1 212 216 179  94   1  50   1 147 205 134\n",
            "   1  26  74  36  33 102   1  28 172 164  89  51 202  63 210  44  39 351\n",
            " 280 245 167  43  57 114  65  82 133 332 317 249 213 188  17   1 110   1\n",
            " 107   1   1 135   1 125  92  60  75 178   1  54 303 353 364 372 369 366\n",
            " 312 241 254  23 193   1 300   1  66  91   1  97 354 345 323  52 170  73\n",
            " 315 185 186 264 256 232 247 229 308 253 319 309 347 103   4 334   1  29\n",
            "  49  61 215  59  86  20 155   8 108   1 263 250 140 197 122 349 150 238\n",
            " 324 294 296 175 325 341 275   1 330   1 269 282 297 304 318 358 370 371\n",
            " 129 230 104  62  78 154 152 148 153 262   1 295 291 355 335 337 199 196\n",
            " 237  70  25 132 180 137   1  69 273 287 121 139  90 276 206 321 339  95\n",
            " 271  88 144 217 141 201 131 211 352 331   3  93 235 151 195 128 259   1\n",
            " 261  37 281 231 228 194 266 218 220 288 138 239 233 278   1 244  64 277\n",
            " 243 265 192 267 227 219 298 127 248 246 101  16  48   6  87  71 116 258\n",
            " 143   1   1 316 290 149 146]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seleccting best features for modeling"
      ],
      "metadata": {
        "id": "uyDxCRamH9bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of feature ranking\n",
        "feature_ranking = [18, 24, 100, 165, 177, 124, 1, 1, 1, 1, 1, 1, 1, 326, 35, 46, 1, 1, 187, 234, 173, 12, 19, 112, 1, 189,\n",
        "                   208, 158, 1, 42, 79, 157, 27, 142, 1, 5, 83, 162, 76, 85, 207, 11, 204, 14, 68, 342, 284, 252, 98, 34,\n",
        "                   55, 136, 117, 115, 105, 343, 292, 251, 223, 174, 9, 1, 119, 1, 160, 41, 1, 58, 1, 166, 99, 32, 72,\n",
        "                   181, 77, 81, 301, 346, 363, 357, 362, 368, 322, 260, 274, 22, 168, 1, 310, 1, 2, 47, 1, 106, 340, 306,\n",
        "                   359, 13, 182, 130, 293, 190, 198, 242, 268, 224, 226, 240, 307, 257, 360, 314, 361, 113, 31, 286, 1,\n",
        "                   1, 40, 171, 183, 56, 96, 21, 145, 7, 120, 38, 236, 255, 80, 191, 156, 327, 169, 221, 299, 285, 305,\n",
        "                   209, 344, 333, 279, 1, 350, 1, 200, 289, 311, 320, 348, 356, 365, 367, 161, 222, 123, 53, 111, 163,\n",
        "                   126, 109, 176, 272, 1, 338, 302, 336, 329, 328, 214, 203, 225, 30, 15, 118, 159, 184, 45, 67, 270,\n",
        "                   283, 10, 313, 1, 84, 1, 1, 212, 216, 179, 94, 1, 50, 1, 147, 205, 134, 1, 26, 74, 36, 33, 102, 1, 28,\n",
        "                   172, 164, 89, 51, 202, 63, 210, 44, 39, 351, 280, 245, 167, 43, 57, 114, 65, 82, 133, 332, 317, 249,\n",
        "                   213, 188, 17, 1, 110, 1, 107, 1, 1, 135, 1, 125, 92, 60, 75, 178, 1, 54, 303, 353, 364, 372, 369, 366,\n",
        "                   312, 241, 254, 23, 193, 1, 300, 1, 66, 91, 1, 97, 354, 345, 323, 52, 170, 73, 315, 185, 186, 264, 256,\n",
        "                   232, 247, 229, 308, 253, 319, 309, 347, 103, 4, 334, 1, 29, 49, 61, 215, 59, 86, 20, 155, 8, 108, 1,\n",
        "                   263, 250, 140, 197, 122, 349, 150, 238, 324, 294, 296, 175, 325, 341, 275, 1, 330, 1, 269, 282, 297,\n",
        "                   304, 318, 358, 370, 371, 129, 230, 104, 62, 78, 154, 152, 148, 153, 262, 1, 295, 291, 355, 335, 337,\n",
        "                   199, 196, 237, 70, 25, 132, 180, 137, 1, 69, 273, 287, 121, 139, 90, 276, 206, 321, 339, 95, 271, 88,\n",
        "                   144, 217, 141, 201, 131, 211, 352, 331, 3, 93, 235, 151, 195, 128, 259, 1, 261, 37, 281, 231, 228,\n",
        "                   194, 266, 218, 220, 288, 138, 239, 233, 278, 1, 244, 64, 277, 243, 265, 192, 267, 227, 219, 298, 127,\n",
        "                   248, 246, 101, 16, 48, 6, 87, 71, 116, 258, 143, 1, 1, 316, 290, 149, 146]\n",
        "\n",
        "# Define X by dropping the 'result' column\n",
        "X = data.drop(columns=['result'])\n",
        "\n",
        "# Define y as the 'result' column\n",
        "y = data['result']\n",
        "\n",
        "# Create a DataFrame with features and their rankings\n",
        "feature_rankings = pd.DataFrame({\n",
        "    'Feature': X.columns,  # The feature names\n",
        "    'Ranking': feature_ranking  # The rankings from RFE\n",
        "})\n",
        "\n",
        "# Sort the features by their ranking\n",
        "feature_rankings = feature_rankings.sort_values(by='Ranking')\n",
        "\n",
        "# Select features with a ranking less than or equal to 5\n",
        "important_features = feature_rankings[feature_rankings['Ranking'] <= 5]['Feature']\n",
        "important_features_list = important_features.tolist()\n",
        "\n",
        "print(\"Selected Important Features with Ranking <= 5:\\n\", important_features_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_djV15B361Jk",
        "outputId": "ec2fe634-595c-4183-878f-19f5dc372bf4"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Important Features with Ranking <= 5:\n",
            " ['home_touchdowns_total', 'away_passing_totals_net_yards', 'away_efficiency_thirddown_pct', 'away_field_goals_totals_yards', 'home_receiving_totals_avg_yards', 'home_field_goals_totals_yards', 'home_field_goals_totals_avg_yards', 'away_receiving_totals_avg_yards', 'away_kick_returns_totals_yards', 'away_rushing_totals_kneel_downs', 'home_passing_totals_avg_yards', 'away_kickoffs_totals_number', 'home_kickoffs_totals_yards', 'home_passing_totals_rating', 'home_rushing_totals_kneel_downs', 'away_return_yards', 'home_passing_totals_cmp_pct', 'home_passing_totals_attempts', 'away_passing_totals_attempts', 'away_passing_totals_cmp_pct', 'away_passing_totals_sack_yards', 'away_passing_totals_rating', 'home_extra_points_kicks_totals_made', 'away_passing_totals_avg_yards', 'home_extra_points_kicks_totals_attempts', 'away_kickoffs_totals_yards', 'home_rushing_totals_yards', 'away_touchdowns_total', 'home_kickoffs_totals_number', 'away_extra_points_kicks_totals_made', 'away_rushing_totals_attempts', 'away_possession_time_seconds', 'home_possession_time_seconds', 'away_rushing_totals_yards', 'home_used_timeouts', 'home_remaining_timeouts', 'home_points', 'away_used_timeouts', 'away_remaining_timeouts', 'away_points', 'home_avg_gain', 'away_total_yards', 'away_defense_totals_passes_defended', 'away_extra_points_kicks_totals_attempts', 'home_total_yards', 'away_rush_plays', 'away_turnovers', 'home_kick_returns_totals_yards', 'home_rush_plays', 'home_rushing_totals_attempts', 'home_kickoffs_totals_total_endzone', 'home_defense_totals_def_targets', 'away_field_goals_totals_made', 'home_receiving_totals_yards']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "cP1Ai_ZnNuZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listing out all the important features for feature engineering\n",
        "important_features_list = ['home_touchdowns_total', 'away_passing_totals_net_yards', 'away_efficiency_thirddown_pct', 'away_field_goals_totals_yards', 'home_receiving_totals_avg_yards',\n",
        "                       'home_field_goals_totals_yards', 'home_field_goals_totals_avg_yards', 'away_receiving_totals_avg_yards', 'away_kick_returns_totals_yards',\n",
        "                       'away_rushing_totals_kneel_downs', 'home_passing_totals_avg_yards', 'away_kickoffs_totals_number', 'home_kickoffs_totals_yards', 'home_passing_totals_rating',\n",
        "                       'home_rushing_totals_kneel_downs', 'away_return_yards', 'home_passing_totals_cmp_pct', 'home_passing_totals_attempts', 'away_passing_totals_attempts',\n",
        "                       'away_passing_totals_cmp_pct', 'away_passing_totals_sack_yards', 'away_passing_totals_rating', 'home_extra_points_kicks_totals_made',\n",
        "                       'away_passing_totals_avg_yards', 'home_extra_points_kicks_totals_attempts', 'away_kickoffs_totals_yards', 'home_rushing_totals_yards', 'away_touchdowns_total',\n",
        "                       'home_kickoffs_totals_number', 'away_extra_points_kicks_totals_made', 'away_rushing_totals_attempts', 'away_possession_time_seconds',\n",
        "                       'home_possession_time_seconds', 'away_rushing_totals_yards', 'home_used_timeouts', 'home_remaining_timeouts', 'home_points', 'away_used_timeouts',\n",
        "                       'away_remaining_timeouts', 'away_points', 'home_avg_gain', 'away_total_yards', 'away_defense_totals_passes_defended', 'away_extra_points_kicks_totals_attempts',\n",
        "                       'home_total_yards', 'away_rush_plays', 'away_turnovers', 'home_kick_returns_totals_yards', 'home_rush_plays', 'home_rushing_totals_attempts',\n",
        "                       'home_kickoffs_totals_total_endzone', 'home_defense_totals_def_targets', 'away_field_goals_totals_made', 'home_receiving_totals_yards',\n",
        "                       'attendance', 'quarter', 'season_year', 'week_sequence', 'week_title', 'venue_capacity', 'venue_location_lat', 'venue_location_lng',\n",
        "                       'home_name_encoded', 'away_name_encoded', 'venue_surface_encoded','venue_roof_type_encoded', 'year', 'month', 'day']\n",
        "\n",
        "# Dataframe 'df' contains 54 features\n",
        "df = data[important_features_list]\n",
        "\n",
        "# Historical averages over the last N games (e.g., 5 games)\n",
        "df['home_avg_points_last_5'] = df.groupby('home_name_encoded')['home_points'].rolling(5).mean().reset_index(level=0, drop=True)\n",
        "df['away_avg_points_last_5'] = df.groupby('away_name_encoded')['away_points'].rolling(5).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "# Recent form (e.g., percentage of maximum points in the last 5 games)\n",
        "df['home_recent_form'] = df.groupby('home_name_encoded')['home_points'].rolling(5).sum().reset_index(level=0, drop=True) / 15  # Assuming 3 points for a win\n",
        "df['away_recent_form'] = df.groupby('away_name_encoded')['away_points'].rolling(5).sum().reset_index(level=0, drop=True) / 15\n",
        "\n",
        "# Scoring and Points\n",
        "df['point_difference'] = df['home_points'] - df['away_points']\n",
        "df['total_points'] = df['home_points'] + df['away_points']\n",
        "df['home_scoring_efficiency'] = df['home_points'] / df['home_total_yards']\n",
        "df['away_scoring_efficiency'] = df['away_points'] / df['away_total_yards']\n",
        "\n",
        "# Offensive Efficiency\n",
        "df['home_avg_yards_per_play'] = df['home_total_yards'] / df['home_rush_plays']\n",
        "df['away_avg_yards_per_play'] = df['away_total_yards'] / df['away_rush_plays']\n",
        "df['home_rush_efficiency'] = df['home_rushing_totals_yards'] / df['home_rushing_totals_attempts']\n",
        "df['away_rush_efficiency'] = df['away_rushing_totals_yards'] / df['away_rushing_totals_attempts']\n",
        "\n",
        "# Defensive Metrics\n",
        "df['home_defense_effectiveness'] = df['away_total_yards'] / df['home_defense_totals_def_targets']\n",
        "df['away_defense_effectiveness'] = df['home_total_yards'] / df['away_defense_totals_passes_defended']\n",
        "\n",
        "# Special Teams Performance\n",
        "df['home_kick_return_yards_per_attempt'] = df['home_kick_returns_totals_yards'] / df['home_kickoffs_totals_number']\n",
        "df['away_kick_return_yards_per_attempt'] = df['away_kick_returns_totals_yards'] / df['away_kickoffs_totals_number']\n",
        "\n",
        "# Possession and Time Management\n",
        "df['possession_difference'] = df['home_possession_time_seconds'] - df['away_possession_time_seconds']\n",
        "df['home_time_per_play'] = df['home_possession_time_seconds'] / (df['home_rush_plays'] + df['home_passing_totals_attempts'])\n",
        "df['away_time_per_play'] = df['away_possession_time_seconds'] / (df['away_rush_plays'] + df['away_passing_totals_attempts'])\n",
        "\n",
        "# Turnover Analysis\n",
        "df['turnover_difference'] = df['away_turnovers'] - df['home_rushing_totals_attempts']\n",
        "\n",
        "# Third Down Efficiency\n",
        "df['third_down_success_difference'] = df['home_rush_plays'] - df['away_efficiency_thirddown_pct']\n",
        "\n",
        "# Red Zone Performance\n",
        "df['home_red_zone_efficiency'] = df['home_touchdowns_total'] / (df['home_rush_plays'] + df['home_passing_totals_attempts'])\n",
        "df['away_red_zone_efficiency'] = df['away_touchdowns_total'] / (df['away_rush_plays'] + df['away_passing_totals_attempts'])\n",
        "\n",
        "# Yardage Metrics\n",
        "df['total_yards_difference'] = df['home_total_yards'] - df['away_total_yards']\n",
        "df['rushing_yards_difference'] = df['home_rushing_totals_yards'] - df['away_rushing_totals_yards']\n",
        "df['passing_yards_difference'] = df['home_passing_totals_avg_yards'] - df['away_passing_totals_avg_yards']\n",
        "\n",
        "# Timeouts and Time Management\n",
        "df['home_timeouts_left_ratio'] = df['home_remaining_timeouts'] / df['home_used_timeouts']\n",
        "df['away_timeouts_left_ratio'] = df['away_remaining_timeouts'] / df['away_used_timeouts']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DQfmd4HW61HN",
        "outputId": "d27e26c9-a702-4b8a-f5a1-f61bfcb69cdc"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-123-e7e72fc57a7b>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['home_avg_points_last_5'] = df.groupby('home_name_encoded')['home_points'].rolling(5).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-123-e7e72fc57a7b>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['away_avg_points_last_5'] = df.groupby('away_name_encoded')['away_points'].rolling(5).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-123-e7e72fc57a7b>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['home_recent_form'] = df.groupby('home_name_encoded')['home_points'].rolling(5).sum().reset_index(level=0, drop=True) / 15  # Assuming 3 points for a win\n",
            "<ipython-input-123-e7e72fc57a7b>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['away_recent_form'] = df.groupby('away_name_encoded')['away_points'].rolling(5).sum().reset_index(level=0, drop=True) / 15\n",
            "<ipython-input-123-e7e72fc57a7b>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['point_difference'] = df['home_points'] - df['away_points']\n",
            "<ipython-input-123-e7e72fc57a7b>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['total_points'] = df['home_points'] + df['away_points']\n",
            "<ipython-input-123-e7e72fc57a7b>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['home_scoring_efficiency'] = df['home_points'] / df['home_total_yards']\n",
            "<ipython-input-123-e7e72fc57a7b>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['away_scoring_efficiency'] = df['away_points'] / df['away_total_yards']\n",
            "<ipython-input-123-e7e72fc57a7b>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['home_avg_yards_per_play'] = df['home_total_yards'] / df['home_rush_plays']\n",
            "<ipython-input-123-e7e72fc57a7b>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['away_avg_yards_per_play'] = df['away_total_yards'] / df['away_rush_plays']\n",
            "<ipython-input-123-e7e72fc57a7b>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['home_rush_efficiency'] = df['home_rushing_totals_yards'] / df['home_rushing_totals_attempts']\n",
            "<ipython-input-123-e7e72fc57a7b>:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['away_rush_efficiency'] = df['away_rushing_totals_yards'] / df['away_rushing_totals_attempts']\n",
            "<ipython-input-123-e7e72fc57a7b>:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['home_defense_effectiveness'] = df['away_total_yards'] / df['home_defense_totals_def_targets']\n",
            "<ipython-input-123-e7e72fc57a7b>:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['away_defense_effectiveness'] = df['home_total_yards'] / df['away_defense_totals_passes_defended']\n",
            "<ipython-input-123-e7e72fc57a7b>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['home_kick_return_yards_per_attempt'] = df['home_kick_returns_totals_yards'] / df['home_kickoffs_totals_number']\n",
            "<ipython-input-123-e7e72fc57a7b>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['away_kick_return_yards_per_attempt'] = df['away_kick_returns_totals_yards'] / df['away_kickoffs_totals_number']\n",
            "<ipython-input-123-e7e72fc57a7b>:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['possession_difference'] = df['home_possession_time_seconds'] - df['away_possession_time_seconds']\n",
            "<ipython-input-123-e7e72fc57a7b>:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['home_time_per_play'] = df['home_possession_time_seconds'] / (df['home_rush_plays'] + df['home_passing_totals_attempts'])\n",
            "<ipython-input-123-e7e72fc57a7b>:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['away_time_per_play'] = df['away_possession_time_seconds'] / (df['away_rush_plays'] + df['away_passing_totals_attempts'])\n",
            "<ipython-input-123-e7e72fc57a7b>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['turnover_difference'] = df['away_turnovers'] - df['home_rushing_totals_attempts']\n",
            "<ipython-input-123-e7e72fc57a7b>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['third_down_success_difference'] = df['home_rush_plays'] - df['away_efficiency_thirddown_pct']\n",
            "<ipython-input-123-e7e72fc57a7b>:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['home_red_zone_efficiency'] = df['home_touchdowns_total'] / (df['home_rush_plays'] + df['home_passing_totals_attempts'])\n",
            "<ipython-input-123-e7e72fc57a7b>:60: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['away_red_zone_efficiency'] = df['away_touchdowns_total'] / (df['away_rush_plays'] + df['away_passing_totals_attempts'])\n",
            "<ipython-input-123-e7e72fc57a7b>:63: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['total_yards_difference'] = df['home_total_yards'] - df['away_total_yards']\n",
            "<ipython-input-123-e7e72fc57a7b>:64: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['rushing_yards_difference'] = df['home_rushing_totals_yards'] - df['away_rushing_totals_yards']\n",
            "<ipython-input-123-e7e72fc57a7b>:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['passing_yards_difference'] = df['home_passing_totals_avg_yards'] - df['away_passing_totals_avg_yards']\n",
            "<ipython-input-123-e7e72fc57a7b>:68: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['home_timeouts_left_ratio'] = df['home_remaining_timeouts'] / df['home_used_timeouts']\n",
            "<ipython-input-123-e7e72fc57a7b>:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['away_timeouts_left_ratio'] = df['away_remaining_timeouts'] / df['away_used_timeouts']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XakEF8_ZuLuc",
        "outputId": "cd6d97a4-b3fc-45f7-a374-d7dd97a94c74"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['home_touchdowns_total', 'away_passing_totals_net_yards', 'away_efficiency_thirddown_pct', 'away_field_goals_totals_yards', 'home_receiving_totals_avg_yards', 'home_field_goals_totals_yards', 'home_field_goals_totals_avg_yards', 'away_receiving_totals_avg_yards', 'away_kick_returns_totals_yards', 'away_rushing_totals_kneel_downs', 'home_passing_totals_avg_yards', 'away_kickoffs_totals_number', 'home_kickoffs_totals_yards', 'home_passing_totals_rating', 'home_rushing_totals_kneel_downs', 'away_return_yards', 'home_passing_totals_cmp_pct', 'home_passing_totals_attempts', 'away_passing_totals_attempts', 'away_passing_totals_cmp_pct', 'away_passing_totals_sack_yards', 'away_passing_totals_rating', 'home_extra_points_kicks_totals_made', 'away_passing_totals_avg_yards', 'home_extra_points_kicks_totals_attempts', 'away_kickoffs_totals_yards', 'home_rushing_totals_yards', 'away_touchdowns_total', 'home_kickoffs_totals_number', 'away_extra_points_kicks_totals_made', 'away_rushing_totals_attempts', 'away_possession_time_seconds', 'home_possession_time_seconds', 'away_rushing_totals_yards', 'home_used_timeouts', 'home_remaining_timeouts', 'home_points', 'away_used_timeouts', 'away_remaining_timeouts', 'away_points', 'home_avg_gain', 'away_total_yards', 'away_defense_totals_passes_defended', 'away_extra_points_kicks_totals_attempts', 'home_total_yards', 'away_rush_plays', 'away_turnovers', 'home_kick_returns_totals_yards', 'home_rush_plays', 'home_rushing_totals_attempts', 'home_kickoffs_totals_total_endzone', 'home_defense_totals_def_targets', 'away_field_goals_totals_made', 'home_receiving_totals_yards', 'attendance', 'quarter', 'season_year', 'week_sequence', 'week_title', 'venue_capacity', 'venue_location_lat', 'venue_location_lng', 'home_name_encoded', 'away_name_encoded', 'venue_surface_encoded', 'venue_roof_type_encoded', 'year', 'month', 'day', 'home_avg_points_last_5', 'away_avg_points_last_5', 'home_recent_form', 'away_recent_form', 'point_difference', 'total_points', 'home_scoring_efficiency', 'away_scoring_efficiency', 'home_avg_yards_per_play', 'away_avg_yards_per_play', 'home_rush_efficiency', 'away_rush_efficiency', 'home_defense_effectiveness', 'away_defense_effectiveness', 'home_kick_return_yards_per_attempt', 'away_kick_return_yards_per_attempt', 'possession_difference', 'home_time_per_play', 'away_time_per_play', 'turnover_difference', 'third_down_success_difference', 'home_red_zone_efficiency', 'away_red_zone_efficiency', 'total_yards_difference', 'rushing_yards_difference', 'passing_yards_difference', 'home_timeouts_left_ratio', 'away_timeouts_left_ratio']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of features available before game starts\n",
        "Before_game_features = [\n",
        "    'attendance', 'quarter', 'season_year', 'week_sequence', 'week_title', 'venue_capacity', 'venue_location_lat', 'venue_location_lng',\n",
        "    'home_name_encoded', 'away_name_encoded', 'venue_surface_encoded','venue_roof_type_encoded', 'year', 'month', 'day']\n",
        "\n",
        "# List of all features, it included engineered features and features which will be avaiable before game starts\n",
        "# Features which are commented have infinite values and so are not considered for modeling\n",
        "all_features = [\n",
        "    'home_avg_points_last_5', 'away_avg_points_last_5', 'home_recent_form', 'away_recent_form',\n",
        "    #'point_difference', 'total_points',\n",
        "    'home_scoring_efficiency', 'away_scoring_efficiency',\n",
        "    'home_avg_yards_per_play', 'away_avg_yards_per_play', 'home_rush_efficiency', 'away_rush_efficiency',\n",
        "    #'home_defense_effectiveness', 'away_defense_effectiveness', 'home_kick_return_yards_per_attempt','away_kick_return_yards_per_attempt',\n",
        "    #'possession_difference',\n",
        "    'home_time_per_play',\n",
        "    'away_time_per_play', 'turnover_difference', 'third_down_success_difference', 'home_red_zone_efficiency',\n",
        "    'away_red_zone_efficiency', 'total_yards_difference', 'rushing_yards_difference',\n",
        "    'passing_yards_difference',\n",
        "    #'home_timeouts_left_ratio', 'away_timeouts_left_ratio',\n",
        "    'attendance', 'quarter', 'season_year', 'week_sequence', 'week_title', 'venue_capacity', 'venue_location_lat', 'venue_location_lng',\n",
        "    'home_name_encoded', 'away_name_encoded', 'venue_surface_encoded','venue_roof_type_encoded', 'year', 'month', 'day']"
      ],
      "metadata": {
        "id": "am0en8Th61Cc"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X is the DataFrame containing all features\n",
        "X = df[all_features]\n",
        "\n",
        "# Check for infinite values in X\n",
        "infinite_mask = np.isinf(X)\n",
        "\n",
        "# Get the count of infinite values for each column\n",
        "inf_counts = infinite_mask.sum(axis=0)\n",
        "\n",
        "# Filter out columns with infinite values and get the counts\n",
        "inf_columns_with_counts = inf_counts[inf_counts > 0]\n",
        "\n",
        "# Print the results\n",
        "print(\"Columns with infinite values and their counts in X:\")\n",
        "print(inf_columns_with_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyHkj0JLwko-",
        "outputId": "fdd2dc9b-effe-4e39-b55d-d10e15402017"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with infinite values and their counts in X:\n",
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Features and target\n",
        "X = df[all_features]\n",
        "y = data['result']\n",
        "\n",
        "# One-hot encode the target variable (result)\n",
        "y = to_categorical(y + 1, num_classes=3)  # Shift to make classes 0, 1, 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check for infinite values and replace them with NaN\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "\n",
        "# Option 2: Impute NaN values (mean imputation is one approach)\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# Normalize the feature data again\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#To avoid overfitting, adding dropout layers and regularization\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.5))  # Add dropout to reduce overfitting\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#For imbalanced dataset using class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(np.argmax(y_train, axis=1)), y=np.argmax(y_train, axis=1))\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping], class_weight=class_weights)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE1BkqfQM7OR",
        "outputId": "782072da-a0d8-43ef-a1b0-11ba10c70690"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4700 - loss: 2.4297 - val_accuracy: 0.8324 - val_loss: 1.3936\n",
            "Epoch 2/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6576 - loss: 1.6138 - val_accuracy: 0.8728 - val_loss: 1.1011\n",
            "Epoch 3/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 1.9680 - val_accuracy: 0.8745 - val_loss: 1.0050\n",
            "Epoch 4/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7473 - loss: 1.8666 - val_accuracy: 0.8671 - val_loss: 0.9498\n",
            "Epoch 5/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7629 - loss: 1.3172 - val_accuracy: 0.8687 - val_loss: 0.9072\n",
            "Epoch 6/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7727 - loss: 1.1277 - val_accuracy: 0.8745 - val_loss: 0.8727\n",
            "Epoch 7/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7864 - loss: 1.2777 - val_accuracy: 0.8737 - val_loss: 0.8495\n",
            "Epoch 8/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7944 - loss: 0.9891 - val_accuracy: 0.8695 - val_loss: 0.8364\n",
            "Epoch 9/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7708 - loss: 1.2113 - val_accuracy: 0.8679 - val_loss: 0.8345\n",
            "Epoch 10/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 1.0261 - val_accuracy: 0.8737 - val_loss: 0.8099\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8709 - loss: 0.8286\n",
            "Test Accuracy: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert one-hot encoded predictions back to class labels\n",
        "y_test_classes = np.argmax(y_test, axis=1)  # Convert one-hot encoded test labels back to class labels\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_classes, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFm4ECiw5-az",
        "outputId": "53628278-1882-4198-b6c4-c2bba90680c4"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Confusion Matrix:\n",
            "[[442  26  31]\n",
            " [  0   3   0]\n",
            " [ 57  39 613]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       499\n",
            "           1       0.04      1.00      0.08         3\n",
            "           2       0.95      0.86      0.91       709\n",
            "\n",
            "    accuracy                           0.87      1211\n",
            "   macro avg       0.63      0.92      0.63      1211\n",
            "weighted avg       0.92      0.87      0.90      1211\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recreating model using Focal Loss\n",
        "\n",
        "\n",
        "> To address class imbalance by down-weighting easy examples and focusing training on harder\n",
        "\n"
      ],
      "metadata": {
        "id": "sl-vN-yvboYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Features and target\n",
        "X = df[all_features]\n",
        "y = data['result']\n",
        "\n",
        "# One-hot encode the target variable (result)\n",
        "y = to_categorical(y + 1, num_classes=3)  # Shift to make classes 0, 1, 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check for infinite values and replace them with NaN\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Impute NaN values (mean imputation)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define focal loss function\n",
        "def focal_loss(gamma=2., alpha=.25):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        eps = tf.keras.backend.epsilon()\n",
        "        y_pred = tf.clip_by_value(y_pred, eps, 1. - eps)\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        alpha_t = y_true * alpha + (tf.keras.backend.ones_like(y_true) - y_true) * (1 - alpha)\n",
        "        p_t = y_true * y_pred + (tf.keras.backend.ones_like(y_true) - y_true) * (tf.keras.backend.ones_like(y_true) - y_pred)\n",
        "        fl = - alpha_t * tf.keras.backend.pow((tf.keras.backend.ones_like(y_true) - p_t), gamma) * tf.keras.backend.log(p_t)\n",
        "        return tf.keras.backend.mean(fl)\n",
        "    return focal_loss_fixed\n",
        "\n",
        "#To avoid overfitting, adding dropout layers and regularization\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.3))  # Adjusted dropout rate\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model with focal loss\n",
        "model.compile(optimizer='adam', loss=focal_loss(gamma=2., alpha=.25), metrics=['accuracy'])\n",
        "\n",
        "# Calculate class weights for imbalanced dataset\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(np.argmax(y_train, axis=1)), y=np.argmax(y_train, axis=1))\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # Increased patience\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping], class_weight=class_weights)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Generate confusion matrix and classification report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true_classes, y_pred_classes))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgCduQ6kV9LI",
        "outputId": "2eceafb5-2cdb-4b2b-935c-63b7d2c95786"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5228 - loss: 0.8707 - val_accuracy: 0.8464 - val_loss: 0.3057\n",
            "Epoch 2/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7661 - loss: 0.2321 - val_accuracy: 0.8893 - val_loss: 0.0910\n",
            "Epoch 3/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.0827 - val_accuracy: 0.8993 - val_loss: 0.0477\n",
            "Epoch 4/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8735 - loss: 0.0496 - val_accuracy: 0.9125 - val_loss: 0.0377\n",
            "Epoch 5/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.0464 - val_accuracy: 0.9141 - val_loss: 0.0356\n",
            "Epoch 6/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8615 - loss: 0.0451 - val_accuracy: 0.9092 - val_loss: 0.0341\n",
            "Epoch 7/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.0374 - val_accuracy: 0.9059 - val_loss: 0.0340\n",
            "Epoch 8/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8796 - loss: 0.0449 - val_accuracy: 0.9133 - val_loss: 0.0324\n",
            "Epoch 9/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8785 - loss: 0.0342 - val_accuracy: 0.9001 - val_loss: 0.0326\n",
            "Epoch 10/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8665 - loss: 0.0405 - val_accuracy: 0.9141 - val_loss: 0.0313\n",
            "Epoch 11/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8782 - loss: 0.0373 - val_accuracy: 0.9075 - val_loss: 0.0308\n",
            "Epoch 12/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8909 - loss: 0.0386 - val_accuracy: 0.9182 - val_loss: 0.0307\n",
            "Epoch 13/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8892 - loss: 0.0351 - val_accuracy: 0.9158 - val_loss: 0.0312\n",
            "Epoch 14/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8922 - loss: 0.0365 - val_accuracy: 0.9149 - val_loss: 0.0301\n",
            "Epoch 15/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8809 - loss: 0.0351 - val_accuracy: 0.8827 - val_loss: 0.0327\n",
            "Epoch 16/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.0356 - val_accuracy: 0.9232 - val_loss: 0.0291\n",
            "Epoch 17/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.0316 - val_accuracy: 0.9257 - val_loss: 0.0288\n",
            "Epoch 18/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8852 - loss: 0.0336 - val_accuracy: 0.8786 - val_loss: 0.0325\n",
            "Epoch 19/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8870 - loss: 0.0305 - val_accuracy: 0.9116 - val_loss: 0.0292\n",
            "Epoch 20/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8935 - loss: 0.0356 - val_accuracy: 0.9199 - val_loss: 0.0276\n",
            "Epoch 21/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8864 - loss: 0.0346 - val_accuracy: 0.9298 - val_loss: 0.0285\n",
            "Epoch 22/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.0372 - val_accuracy: 0.9207 - val_loss: 0.0279\n",
            "Epoch 23/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.0343 - val_accuracy: 0.9158 - val_loss: 0.0275\n",
            "Epoch 24/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8812 - loss: 0.0402 - val_accuracy: 0.9182 - val_loss: 0.0281\n",
            "Epoch 25/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.0282 - val_accuracy: 0.9149 - val_loss: 0.0295\n",
            "Epoch 26/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9005 - loss: 0.0319 - val_accuracy: 0.9182 - val_loss: 0.0282\n",
            "Epoch 27/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8987 - loss: 0.0348 - val_accuracy: 0.9108 - val_loss: 0.0296\n",
            "Epoch 28/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9023 - loss: 0.0318 - val_accuracy: 0.9100 - val_loss: 0.0282\n",
            "Epoch 29/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.0332 - val_accuracy: 0.9199 - val_loss: 0.0277\n",
            "Epoch 30/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.0295 - val_accuracy: 0.9257 - val_loss: 0.0265\n",
            "Epoch 31/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.0292 - val_accuracy: 0.9182 - val_loss: 0.0275\n",
            "Epoch 32/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9018 - loss: 0.0297 - val_accuracy: 0.9323 - val_loss: 0.0267\n",
            "Epoch 33/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9062 - loss: 0.0348 - val_accuracy: 0.9306 - val_loss: 0.0258\n",
            "Epoch 34/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.0367 - val_accuracy: 0.9009 - val_loss: 0.0273\n",
            "Epoch 35/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 0.0295 - val_accuracy: 0.9059 - val_loss: 0.0280\n",
            "Epoch 36/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.0360 - val_accuracy: 0.9199 - val_loss: 0.0261\n",
            "Epoch 37/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9091 - loss: 0.0305 - val_accuracy: 0.9207 - val_loss: 0.0265\n",
            "Epoch 38/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.0330 - val_accuracy: 0.9108 - val_loss: 0.0266\n",
            "Epoch 39/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.0330 - val_accuracy: 0.9207 - val_loss: 0.0271\n",
            "Epoch 40/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.0308 - val_accuracy: 0.9290 - val_loss: 0.0257\n",
            "Epoch 41/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.0261 - val_accuracy: 0.9224 - val_loss: 0.0270\n",
            "Epoch 42/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9046 - loss: 0.0317 - val_accuracy: 0.9232 - val_loss: 0.0259\n",
            "Epoch 43/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.0279 - val_accuracy: 0.9323 - val_loss: 0.0261\n",
            "Epoch 44/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.0279 - val_accuracy: 0.9075 - val_loss: 0.0279\n",
            "Epoch 45/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.0285 - val_accuracy: 0.9191 - val_loss: 0.0269\n",
            "Epoch 46/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.0335 - val_accuracy: 0.9273 - val_loss: 0.0248\n",
            "Epoch 47/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.0277 - val_accuracy: 0.9306 - val_loss: 0.0261\n",
            "Epoch 48/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.0323 - val_accuracy: 0.9306 - val_loss: 0.0251\n",
            "Epoch 49/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.0299 - val_accuracy: 0.9381 - val_loss: 0.0241\n",
            "Epoch 50/50\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.0280 - val_accuracy: 0.9290 - val_loss: 0.0262\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9377 - loss: 0.0248 \n",
            "Test Accuracy: 0.94\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Confusion Matrix:\n",
            "[[453   0  46]\n",
            " [  1   0   2]\n",
            " [ 26   0 683]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93       499\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.93      0.96      0.95       709\n",
            "\n",
            "    accuracy                           0.94      1211\n",
            "   macro avg       0.63      0.62      0.62      1211\n",
            "weighted avg       0.94      0.94      0.94      1211\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to Retrieve Historical Data\n"
      ],
      "metadata": {
        "id": "j12wmRhdWQjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_historical_data(home_team, away_team, game_date, historical_df, lookback_games=5):\n",
        "    # Unpack the game_date tuple\n",
        "    game_year, game_month, game_day = game_date\n",
        "\n",
        "    # Filter past games for the home and away teams before the given game date\n",
        "    past_games_home = historical_df[\n",
        "        (historical_df['home_name_encoded'] == home_team) &\n",
        "        (\n",
        "            (historical_df['year'] < game_year) |\n",
        "            ((historical_df['year'] == game_year) & (historical_df['month'] < game_month)) |\n",
        "            ((historical_df['year'] == game_year) & (historical_df['month'] == game_month) & (historical_df['day'] < game_day))\n",
        "        )\n",
        "    ].sort_values(by=['year', 'month', 'day'], ascending=False).head(lookback_games)\n",
        "\n",
        "    past_games_away = historical_df[\n",
        "        (historical_df['away_name_encoded'] == away_team) &\n",
        "        (\n",
        "            (historical_df['year'] < game_year) |\n",
        "            ((historical_df['year'] == game_year) & (historical_df['month'] < game_month)) |\n",
        "            ((historical_df['year'] == game_year) & (historical_df['month'] == game_month) & (historical_df['day'] < game_day))\n",
        "        )\n",
        "    ].sort_values(by=['year', 'month', 'day'], ascending=False).head(lookback_games)\n",
        "\n",
        "    # Calculate historical features (unchanged)\n",
        "    home_avg_points_last_5 = past_games_home['home_points'].mean()\n",
        "    away_avg_points_last_5 = past_games_away['away_points'].mean()\n",
        "    home_recent_form = past_games_home['home_points'].sum() / (lookback_games * 3)  # Assuming 3 points per win\n",
        "    away_recent_form = past_games_away['away_points'].sum() / (lookback_games * 3)\n",
        "\n",
        "    home_scoring_efficiency = past_games_home['home_points'].sum() / past_games_home['home_total_yards'].sum()\n",
        "    away_scoring_efficiency = past_games_away['away_points'].sum() / past_games_away['away_total_yards'].sum()\n",
        "\n",
        "    home_avg_yards_per_play = past_games_home['home_total_yards'].sum() / past_games_home['home_rush_plays'].sum()\n",
        "    away_avg_yards_per_play = past_games_away['away_total_yards'].sum() / past_games_away['away_rush_plays'].sum()\n",
        "\n",
        "    home_rush_efficiency = past_games_home['home_rushing_totals_yards'].sum() / past_games_home['home_rushing_totals_attempts'].sum()\n",
        "    away_rush_efficiency = past_games_away['away_rushing_totals_yards'].sum() / past_games_away['away_rushing_totals_attempts'].sum()\n",
        "\n",
        "    #home_defense_effectiveness = past_games_away['away_total_yards'].sum() / past_games_home['home_defense_totals_def_targets'].sum()\n",
        "    #away_defense_effectiveness = past_games_home['home_total_yards'].sum() / past_games_away['away_defense_totals_passes_defended'].sum()\n",
        "\n",
        "    #home_kick_return_yards_per_attempt = past_games_home['home_kick_returns_totals_yards'].sum() / past_games_home['home_kickoffs_totals_number'].sum()\n",
        "    #away_kick_return_yards_per_attempt = past_games_away['away_kick_returns_totals_yards'].sum() / past_games_away['away_kickoffs_totals_number'].sum()\n",
        "\n",
        "    home_time_per_play = past_games_home['home_possession_time_seconds'].sum() / (past_games_home['home_rush_plays'].sum() + past_games_home['home_passing_totals_attempts'].sum())\n",
        "    away_time_per_play = past_games_away['away_possession_time_seconds'].sum() / (past_games_away['away_rush_plays'].sum() + past_games_away['away_passing_totals_attempts'].sum())\n",
        "\n",
        "    turnover_difference = past_games_away['away_turnovers'].sum() - past_games_home['home_rushing_totals_attempts'].sum()\n",
        "\n",
        "    third_down_success_difference = past_games_home['home_rush_plays'].sum() - past_games_away['away_efficiency_thirddown_pct'].sum()\n",
        "\n",
        "    home_red_zone_efficiency = past_games_home['home_touchdowns_total'].sum() / (past_games_home['home_rush_plays'].sum() + past_games_home['home_passing_totals_attempts'].sum())\n",
        "    away_red_zone_efficiency = past_games_away['away_touchdowns_total'].sum() / (past_games_away['away_rush_plays'].sum() + past_games_away['away_passing_totals_attempts'].sum())\n",
        "\n",
        "    total_yards_difference = past_games_home['home_total_yards'].sum() - past_games_away['away_total_yards'].sum()\n",
        "    rushing_yards_difference = past_games_home['home_rushing_totals_yards'].sum() - past_games_away['away_rushing_totals_yards'].sum()\n",
        "    passing_yards_difference = past_games_home['home_passing_totals_avg_yards'].sum() - past_games_away['away_passing_totals_avg_yards'].sum()\n",
        "\n",
        "   #home_timeouts_left_ratio = past_games_home['home_remaining_timeouts'].sum() / past_games_home['home_used_timeouts'].sum()\n",
        "   #away_timeouts_left_ratio = past_games_away['away_remaining_timeouts'].sum() / past_games_away['away_used_timeouts'].sum()\n",
        "\n",
        "    # Combine all historical features into a dictionary\n",
        "    historical_features = {\n",
        "        'home_avg_points_last_5': home_avg_points_last_5,\n",
        "        'away_avg_points_last_5': away_avg_points_last_5,\n",
        "        'home_recent_form': home_recent_form,\n",
        "        'away_recent_form': away_recent_form,\n",
        "        'home_scoring_efficiency': home_scoring_efficiency,\n",
        "        'away_scoring_efficiency': away_scoring_efficiency,\n",
        "        'home_avg_yards_per_play': home_avg_yards_per_play,\n",
        "        'away_avg_yards_per_play': away_avg_yards_per_play,\n",
        "        'home_rush_efficiency': home_rush_efficiency,\n",
        "        'away_rush_efficiency': away_rush_efficiency,\n",
        "        #'home_defense_effectiveness': home_defense_effectiveness,\n",
        "        #'away_defense_effectiveness': away_defense_effectiveness,\n",
        "        #'home_kick_return_yards_per_attempt': home_kick_return_yards_per_attempt,\n",
        "        #'away_kick_return_yards_per_attempt': away_kick_return_yards_per_attempt,\n",
        "        'home_time_per_play': home_time_per_play,\n",
        "        'away_time_per_play': away_time_per_play,\n",
        "        'turnover_difference': turnover_difference,\n",
        "        'third_down_success_difference': third_down_success_difference,\n",
        "        'home_red_zone_efficiency': home_red_zone_efficiency,\n",
        "        'away_red_zone_efficiency': away_red_zone_efficiency,\n",
        "        'total_yards_difference': total_yards_difference,\n",
        "        'rushing_yards_difference': rushing_yards_difference,\n",
        "        'passing_yards_difference': passing_yards_difference,\n",
        "        #'home_timeouts_left_ratio': home_timeouts_left_ratio,\n",
        "        #'away_timeouts_left_ratio': away_timeouts_left_ratio\n",
        "    }\n",
        "\n",
        "    return historical_features\n"
      ],
      "metadata": {
        "id": "cC5IC29vnEZi"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine Before-game Features with Historical Features\n"
      ],
      "metadata": {
        "id": "CtJySz3ZWiFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def create_feature_vector(home_team, away_team, before_game_features, game_date, historical_df, scaler):\n",
        "    # Retrieve historical features\n",
        "    historical_features = retrieve_historical_data(home_team, away_team, game_date, historical_df)\n",
        "\n",
        "    # Combine before-game features with historical features\n",
        "    feature_vector = {**historical_features, **before_game_features}\n",
        "\n",
        "    # Convert to DataFrame for model input\n",
        "    feature_vector_df = pd.DataFrame([feature_vector])\n",
        "\n",
        "    # Check for infinite values and replace them with NaN\n",
        "    feature_vector_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # Impute NaN values (mean imputation)\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    feature_vector_imputed = pd.DataFrame(imputer.fit_transform(feature_vector_df), columns=feature_vector_df.columns)\n",
        "\n",
        "    # Scale the features\n",
        "    feature_vector_scaled = pd.DataFrame(scaler.transform(feature_vector_imputed), columns=feature_vector_imputed.columns)\n",
        "\n",
        "    return feature_vector_scaled"
      ],
      "metadata": {
        "id": "UqGp5wyBWPXU"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction Function\n"
      ],
      "metadata": {
        "id": "U0SoBPblWlvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_game_outcome(home_team, away_team, before_game_features, game_date, historical_df, model, scaler):\n",
        "    # Create the feature vector\n",
        "    feature_vector_df = create_feature_vector(home_team, away_team, before_game_features, game_date, historical_df, scaler)\n",
        "\n",
        "    # Make the prediction\n",
        "    prediction = model.predict(feature_vector_df)\n",
        "\n",
        "    # Get the index of the highest probability class\n",
        "    predicted_class = np.argmax(prediction, axis=1)[0]  # Extract the class index (0, 1, or 2)\n",
        "\n",
        "    # Map the predicted class index to the corresponding label\n",
        "    prediction_label = \"Home Win\" if predicted_class == 2 else \"Away Win\" if predicted_class == 0 else \"Draw\"\n",
        "    return prediction_label"
      ],
      "metadata": {
        "id": "YRjcc-dmWPUp"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Test Dataset"
      ],
      "metadata": {
        "id": "mOBFRF8pb1Ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the list of columns you want to keep\n",
        "Before_game_features = [\n",
        "    'attendance', 'quarter', 'season_year', 'week_sequence', 'week_title', 'venue_capacity',\n",
        "    'venue_location_lat', 'venue_location_lng', 'home_name_encoded', 'away_name_encoded',\n",
        "    'venue_surface_encoded', 'venue_roof_type_encoded', 'year', 'month', 'day', 'result'\n",
        "]\n",
        "\n",
        "# Select only the columns from Before_game_features\n",
        "df_filtered = data[Before_game_features]\n",
        "\n",
        "# Sort by a date column or sequence column to ensure the most recent rows are at the bottom\n",
        "df_filtered_sorted = df_filtered.sort_values(by=['season_year', 'month', 'day'], ascending=[True, True, True])\n",
        "\n",
        "# Take the most recent 5% of the rows\n",
        "recent_5_percent_index = int(len(df_filtered_sorted) * 0.95)\n",
        "X_test_recent = df_filtered_sorted.iloc[recent_5_percent_index:]\n",
        "\n",
        "# Reset the index of X_test\n",
        "X_test_recent.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display X_test to verify the result\n",
        "X_test_recent.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "ChQ0myuYQ4SE",
        "outputId": "2d361e08-b9c8-4176-cbc7-849f88a215d1"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   attendance  quarter  season_year  week_sequence  week_title  \\\n",
              "0     67431.0      4.0       2022.0           15.0        15.0   \n",
              "1     70794.0      4.0       2022.0           15.0        15.0   \n",
              "2     70541.0      5.0       2022.0           15.0        15.0   \n",
              "3     73548.0      4.0       2022.0           15.0        15.0   \n",
              "4     75076.0      4.0       2022.0           15.0        15.0   \n",
              "\n",
              "   venue_capacity  venue_location_lat  venue_location_lng  home_name_encoded  \\\n",
              "0         67895.0           41.506054          -81.700004                  5   \n",
              "1         71608.0           42.773826          -78.786589                  3   \n",
              "2         72220.0           29.684735          -95.410725                 31   \n",
              "3         74867.0           35.225937          -80.853133                 22   \n",
              "4         82500.0           40.813611          -74.074444                 19   \n",
              "\n",
              "   away_name_encoded  venue_surface_encoded  venue_roof_type_encoded    year  \\\n",
              "0                 26                      1                        1  2022.0   \n",
              "1                 13                      0                        1  2022.0   \n",
              "2                  9                      0                        2  2022.0   \n",
              "3                 30                      0                        1  2022.0   \n",
              "4                 20                      0                        1  2022.0   \n",
              "\n",
              "   month   day  result  \n",
              "0   12.0  17.0       1  \n",
              "1   12.0  18.0       1  \n",
              "2   12.0  18.0      -1  \n",
              "3   12.0  18.0      -1  \n",
              "4   12.0  18.0      -1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd4b40d9-9886-4e37-bfde-211a38c09135\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attendance</th>\n",
              "      <th>quarter</th>\n",
              "      <th>season_year</th>\n",
              "      <th>week_sequence</th>\n",
              "      <th>week_title</th>\n",
              "      <th>venue_capacity</th>\n",
              "      <th>venue_location_lat</th>\n",
              "      <th>venue_location_lng</th>\n",
              "      <th>home_name_encoded</th>\n",
              "      <th>away_name_encoded</th>\n",
              "      <th>venue_surface_encoded</th>\n",
              "      <th>venue_roof_type_encoded</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67431.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>67895.0</td>\n",
              "      <td>41.506054</td>\n",
              "      <td>-81.700004</td>\n",
              "      <td>5</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>70794.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>71608.0</td>\n",
              "      <td>42.773826</td>\n",
              "      <td>-78.786589</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70541.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>72220.0</td>\n",
              "      <td>29.684735</td>\n",
              "      <td>-95.410725</td>\n",
              "      <td>31</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73548.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>74867.0</td>\n",
              "      <td>35.225937</td>\n",
              "      <td>-80.853133</td>\n",
              "      <td>22</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75076.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>82500.0</td>\n",
              "      <td>40.813611</td>\n",
              "      <td>-74.074444</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd4b40d9-9886-4e37-bfde-211a38c09135')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd4b40d9-9886-4e37-bfde-211a38c09135 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd4b40d9-9886-4e37-bfde-211a38c09135');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-21881a8c-42f1-458e-884a-7cdd26242afc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21881a8c-42f1-458e-884a-7cdd26242afc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-21881a8c-42f1-458e-884a-7cdd26242afc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test_recent",
              "summary": "{\n  \"name\": \"X_test_recent\",\n  \"rows\": 303,\n  \"fields\": [\n    {\n      \"column\": \"attendance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6693.451318574566,\n        \"min\": 48423.0,\n        \"max\": 93754.0,\n        \"num_unique_values\": 267,\n        \"samples\": [\n          66878.0,\n          66292.0,\n          66026.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quarter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22401451223944843,\n        \"min\": 4.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season_year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30355718248902447,\n        \"min\": 2022.0,\n        \"max\": 2023.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2023.0,\n          2022.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"week_sequence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.3530891613723375,\n        \"min\": 1.0,\n        \"max\": 18.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          15.0,\n          16.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"week_title\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.3530891613723375,\n        \"min\": 1.0,\n        \"max\": 18.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          15.0,\n          16.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"venue_capacity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5807.124353300322,\n        \"min\": 48000.0,\n        \"max\": 90000.0,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          90000.0,\n          66829.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"venue_location_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.2808307783664175,\n        \"min\": 25.958025,\n        \"max\": 51.6042,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          39.900872,\n          42.090944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"venue_location_lng\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.418307241978507,\n        \"min\": -122.33165,\n        \"max\": 0.0662,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          -75.167311,\n          -71.264344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"home_name_encoded\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 33,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          15,\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"away_name_encoded\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 0,\n        \"max\": 33,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          0,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"venue_surface_encoded\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"venue_roof_type_encoded\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3959778545614439,\n        \"min\": 2022.0,\n        \"max\": 2024.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2022.0,\n          2024.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.503467313380295,\n        \"min\": 1.0,\n        \"max\": 12.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0,\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.689250303500584,\n        \"min\": 1.0,\n        \"max\": 31.0,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          14.0,\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"result\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -1,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions"
      ],
      "metadata": {
        "id": "eXW_-Q_rcIK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# List to store the predictions\n",
        "predictions = []\n",
        "\n",
        "# Iterate over each row in X_test\n",
        "for index, row in X_test_recent.iterrows():\n",
        "    # Extract the relevant features for the prediction\n",
        "    before_game_features = {\n",
        "        'attendance': row['attendance'],\n",
        "        'quarter': row['quarter'],\n",
        "        'season_year': row['season_year'],\n",
        "        'week_sequence': row['week_sequence'],\n",
        "        'week_title': row['week_title'],\n",
        "        'venue_capacity': row['venue_capacity'],\n",
        "        'venue_location_lat': row['venue_location_lat'],\n",
        "        'venue_location_lng': row['venue_location_lng'],\n",
        "        'home_name_encoded': row['home_name_encoded'],\n",
        "        'away_name_encoded': row['away_name_encoded'],\n",
        "        'venue_surface_encoded': row['venue_surface_encoded'],\n",
        "        'venue_roof_type_encoded': row['venue_roof_type_encoded'],\n",
        "        'year': row['year'],\n",
        "        'month': row['month'],\n",
        "        'day': row['day']\n",
        "    }\n",
        "\n",
        "    # Construct the game_date from year, month, and day\n",
        "    game_date = (row['year'], row['month'], row['day'])  # Just a tuple now\n",
        "\n",
        "    # Predict the game outcome using the extracted features\n",
        "    prediction_label = predict_game_outcome(\n",
        "        row['home_name_encoded'],\n",
        "        row['away_name_encoded'],\n",
        "        before_game_features,\n",
        "        game_date,\n",
        "        df,  #historical data DataFrame\n",
        "        model,\n",
        "        scaler=scaler\n",
        "    )\n",
        "\n",
        "    # Append the prediction to the list\n",
        "    predictions.append(prediction_label)\n",
        "\n",
        "# Add the predictions to X_test DataFrame for comparison\n",
        "X_test_recent['predicted_outcome'] = predictions\n",
        "\n",
        "# Optionally, print the DataFrame to see the predictions\n",
        "print(X_test_recent[['home_name_encoded', 'away_name_encoded', 'predicted_outcome', 'result']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HmcHgOOpSXab",
        "outputId": "082055ce-a185-4830-89ea-e0a0f5ae32c5"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "     home_name_encoded  away_name_encoded predicted_outcome  result\n",
            "0                    5                 26          Home Win       1\n",
            "1                    3                 13          Home Win       1\n",
            "2                   31                  9          Away Win      -1\n",
            "3                   22                 30          Home Win      -1\n",
            "4                   19                 20          Home Win      -1\n",
            "..                 ...                ...               ...     ...\n",
            "298                 31                 32          Home Win       1\n",
            "299                 26                 13          Home Win       1\n",
            "300                 29                 30          Home Win      -1\n",
            "301                  9                  2          Away Win       1\n",
            "302                  4                  8          Home Win       1\n",
            "\n",
            "[303 rows x 4 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-161-d50fdf42ff47>:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_test_recent['predicted_outcome'] = predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Adjust the 'result' column to match the labels\n",
        "# Convert -1 to 0, 0 stays the same, and 1 to 2\n",
        "X_test_recent['result'] = X_test_recent['result'].map({-1: 0, 0: 1, 1: 2})\n",
        "\n",
        "# Print the DataFrame to verify the conversion and predictions\n",
        "print(X_test_recent[['home_name_encoded', 'away_name_encoded', 'predicted_outcome', 'result']])\n",
        "\n",
        "# Calculate the accuracy score\n",
        "# Convert 'predicted_outcome' from labels (\"Home Win\", \"Away Win\", \"Draw\") to numerical values (2, 0, 1)\n",
        "X_test_recent['predicted_outcome_num'] = X_test_recent['predicted_outcome'].map({\"Home Win\": 2, \"Away Win\": 0, \"Draw\": 1})\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(X_test_recent['result'], X_test_recent['predicted_outcome_num'])\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8paHRtRvZAKS",
        "outputId": "9a39736e-6ef2-42c0-bf20-aa9e1807bdbc"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     home_name_encoded  away_name_encoded predicted_outcome  result\n",
            "0                    5                 26          Home Win       2\n",
            "1                    3                 13          Home Win       2\n",
            "2                   31                  9          Away Win       0\n",
            "3                   22                 30          Home Win       0\n",
            "4                   19                 20          Home Win       0\n",
            "..                 ...                ...               ...     ...\n",
            "298                 31                 32          Home Win       2\n",
            "299                 26                 13          Home Win       2\n",
            "300                 29                 30          Home Win       0\n",
            "301                  9                  2          Away Win       2\n",
            "302                  4                  8          Home Win       2\n",
            "\n",
            "[303 rows x 4 columns]\n",
            "Accuracy: 0.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-162-9f2e31983f47>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_test_recent['result'] = X_test_recent['result'].map({-1: 0, 0: 1, 1: 2})\n",
            "<ipython-input-162-9f2e31983f47>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_test_recent['predicted_outcome_num'] = X_test_recent['predicted_outcome'].map({\"Home Win\": 2, \"Away Win\": 0, \"Draw\": 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test_recent['predicted_outcome_num'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynGBO6n-31SK",
        "outputId": "64e73b5e-d423-464a-8c9b-2f9a233b4be2"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_outcome_num\n",
            "2    228\n",
            "0     75\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning\n",
        "\n",
        "\n",
        "> Building Comprehensive Model\n",
        "\n"
      ],
      "metadata": {
        "id": "qRcvI3Z8PBSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.utils import to_categorical\n",
        "from keras.regularizers import l2\n",
        "from sklearn.impute import SimpleImputer\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Features and target\n",
        "X = df[all_features]\n",
        "y = data['result']\n",
        "\n",
        "# One-hot encode the target variable (result)\n",
        "y = to_categorical(y + 1, num_classes=3)  # Shift to make classes 0, 1, 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check for infinite values and replace them with NaN\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Impute NaN values (mean imputation)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the comprehensive model using Functional API\n",
        "input_all = Input(shape=(X_train.shape[1],))\n",
        "x = Dense(128, activation='relu')(input_all)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "output_all = Dense(3, activation='softmax')(x)  # Assuming 3 classes as per y = to_categorical\n",
        "comprehensive_model = Model(inputs=input_all, outputs=output_all)\n",
        "\n",
        "# Compile the model\n",
        "comprehensive_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "comprehensive_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = comprehensive_model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "KUW-F6fbqGYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e61a4c3-2b5e-471c-b418-72d0772812fc"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.5532 - val_accuracy: 0.8976 - val_loss: 0.2297\n",
            "Epoch 2/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8946 - loss: 0.2650 - val_accuracy: 0.9191 - val_loss: 0.1884\n",
            "Epoch 3/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2084 - val_accuracy: 0.9306 - val_loss: 0.1618\n",
            "Epoch 4/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.1995 - val_accuracy: 0.9381 - val_loss: 0.1476\n",
            "Epoch 5/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.1804 - val_accuracy: 0.9513 - val_loss: 0.1310\n",
            "Epoch 6/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.1486 - val_accuracy: 0.9546 - val_loss: 0.1146\n",
            "Epoch 7/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1537 - val_accuracy: 0.9579 - val_loss: 0.1059\n",
            "Epoch 8/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1372 - val_accuracy: 0.9678 - val_loss: 0.0920\n",
            "Epoch 9/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.1100 - val_accuracy: 0.9703 - val_loss: 0.0856\n",
            "Epoch 10/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1093 - val_accuracy: 0.9727 - val_loss: 0.0828\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.0976 \n",
            "Test Accuracy: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer learning from compreensive model to prediction model"
      ],
      "metadata": {
        "id": "pFrHwLA7PN89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming 'data' and 'Before_game_features' are defined and correct\n",
        "X_new = data[Before_game_features]\n",
        "y = data['result']\n",
        "y_new = to_categorical(y + 1, num_classes=3)  # Ensure the correct number of classes\n",
        "\n",
        "new_scaler = StandardScaler()\n",
        "X_new = new_scaler.fit_transform(X_new)\n",
        "\n",
        "# Define new model architecture\n",
        "input_pred = Input(shape=(X_new.shape[1],))\n",
        "x_pred = Dense(128, activation='relu')(input_pred)\n",
        "x_pred = Dropout(0.5)(x_pred)\n",
        "x_pred = Dense(64, activation='relu')(x_pred)\n",
        "x_pred = Dropout(0.5)(x_pred)\n",
        "x_pred = Dense(32, activation='relu')(x_pred)\n",
        "output_pred = Dense(3, activation='softmax')(x_pred)\n",
        "prediction_model = Model(inputs=input_pred, outputs=output_pred)\n",
        "\n",
        "# Filter only 'Dense' layers, skipping the first one\n",
        "comprehensive_model_dense_layers = [layer for layer in comprehensive_model.layers if 'dense' in layer.name][1:]\n",
        "prediction_model_dense_layers = [layer for layer in prediction_model.layers if 'dense' in layer.name][1:]\n",
        "\n",
        "# Transfer weights for compatible layers\n",
        "for comp_layer, pred_layer in zip(comprehensive_model_dense_layers, prediction_model_dense_layers):\n",
        "    if comp_layer.get_config()['units'] == pred_layer.get_config()['units']:\n",
        "        pred_layer.set_weights(comp_layer.get_weights())\n",
        "    else:\n",
        "        print(f\"Skipping weight transfer for layer {comp_layer.name} due to configuration mismatch.\")\n",
        "\n",
        "# Compile and train the new model\n",
        "prediction_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "prediction_model.fit(X_new, y_new, epochs=20, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = prediction_model.evaluate(X_new, y_new)\n",
        "print(f'New Model Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "1drxoXsgM7L-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cdead96-b243-42fb-bba1-407e865ea905"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5518 - loss: 0.7776 - val_accuracy: 0.5301 - val_loss: 0.7269\n",
            "Epoch 2/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5637 - loss: 0.7044 - val_accuracy: 0.5301 - val_loss: 0.7320\n",
            "Epoch 3/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5536 - loss: 0.7011 - val_accuracy: 0.5301 - val_loss: 0.7273\n",
            "Epoch 4/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5596 - loss: 0.7028 - val_accuracy: 0.5301 - val_loss: 0.7276\n",
            "Epoch 5/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5602 - loss: 0.7022 - val_accuracy: 0.5301 - val_loss: 0.7404\n",
            "Epoch 6/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5766 - loss: 0.6924 - val_accuracy: 0.5301 - val_loss: 0.7272\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5660 - loss: 0.6920\n",
            "New Model Accuracy: 0.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Redefine new model\n",
        "new_model = Sequential()\n",
        "# Reinitialize the first layer to match the new feature size\n",
        "new_model.add(Dense(64, activation='relu', input_shape=(X_new.shape[1],)))\n",
        "# Add other layers, possibly transferring weights from the base model if compatible\n",
        "new_model.add(Dense(32, activation='relu'))\n",
        "new_model.add(Dropout(0.3))\n",
        "new_model.add(Dense(16, activation='relu'))\n",
        "new_model.add(Dropout(0.3))\n",
        "new_model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile and train the new model\n",
        "new_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "new_model.fit(X_new, y_new, epochs=20, batch_size=32,  validation_split=0.2)\n",
        "\n",
        "# Evaluate the new model\n",
        "loss, accuracy = new_model.evaluate(X_new, y_new)\n",
        "print(f'New Model Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "JgfGTShDVKJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3c9218-0272-42cd-df7d-5a0f8f96788f"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4430 - loss: 0.9570 - val_accuracy: 0.5301 - val_loss: 0.7260\n",
            "Epoch 2/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5445 - loss: 0.7209 - val_accuracy: 0.5301 - val_loss: 0.7280\n",
            "Epoch 3/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5569 - loss: 0.7083 - val_accuracy: 0.5301 - val_loss: 0.7330\n",
            "Epoch 4/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5581 - loss: 0.7155 - val_accuracy: 0.5301 - val_loss: 0.7429\n",
            "Epoch 5/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5442 - loss: 0.7015 - val_accuracy: 0.5301 - val_loss: 0.7421\n",
            "Epoch 6/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 0.6990 - val_accuracy: 0.5301 - val_loss: 0.7464\n",
            "Epoch 7/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5685 - loss: 0.6982 - val_accuracy: 0.5301 - val_loss: 0.7413\n",
            "Epoch 8/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5643 - loss: 0.7007 - val_accuracy: 0.5301 - val_loss: 0.7431\n",
            "Epoch 9/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5687 - loss: 0.6921 - val_accuracy: 0.5301 - val_loss: 0.7515\n",
            "Epoch 10/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5749 - loss: 0.6989 - val_accuracy: 0.5301 - val_loss: 0.7464\n",
            "Epoch 11/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5762 - loss: 0.6958 - val_accuracy: 0.5343 - val_loss: 0.7437\n",
            "Epoch 12/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5695 - loss: 0.6957 - val_accuracy: 0.5301 - val_loss: 0.7590\n",
            "Epoch 13/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 0.6923 - val_accuracy: 0.5343 - val_loss: 0.7594\n",
            "Epoch 14/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5704 - loss: 0.6899 - val_accuracy: 0.5310 - val_loss: 0.7527\n",
            "Epoch 15/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5666 - loss: 0.6967 - val_accuracy: 0.5326 - val_loss: 0.7587\n",
            "Epoch 16/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5722 - loss: 0.6927 - val_accuracy: 0.5326 - val_loss: 0.7571\n",
            "Epoch 17/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5679 - loss: 0.6970 - val_accuracy: 0.5326 - val_loss: 0.7576\n",
            "Epoch 18/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5726 - loss: 0.6895 - val_accuracy: 0.5351 - val_loss: 0.7580\n",
            "Epoch 19/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5788 - loss: 0.6926 - val_accuracy: 0.5392 - val_loss: 0.7714\n",
            "Epoch 20/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5627 - loss: 0.6968 - val_accuracy: 0.5359 - val_loss: 0.7674\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5675 - loss: 0.6877\n",
            "New Model Accuracy: 0.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Use RandomForest to assess feature importance\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_new, np.argmax(y_new, axis=1))  # Assuming y_new is one-hot encoded\n",
        "\n",
        "# Extract feature importances\n",
        "importances = rf_model.feature_importances_\n",
        "feature_names = Before_game_features\n",
        "\n",
        "# Sort the feature importances in descending order\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print feature rankings and importance scores\n",
        "print(\"Feature Ranking and Importance Scores:\")\n",
        "for i in range(len(feature_names)):\n",
        "    print(f\"{i + 1}. {feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")"
      ],
      "metadata": {
        "id": "nQIKLvS4M7KI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1baa2b18-2e9e-4012-b78a-f82d9bc6c7be"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Ranking and Importance Scores:\n",
            "1. attendance: 0.3305\n",
            "2. away_name_encoded: 0.2176\n",
            "3. day: 0.2089\n",
            "4. season_year: 0.1036\n",
            "5. year: 0.1026\n",
            "6. venue_surface_encoded: 0.0367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting most relevant pre-game features"
      ],
      "metadata": {
        "id": "Hxrfa4U0N7SI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Preprocess the Before_game_features\n",
        "Before_game_features = ['attendance', 'season_year','away_name_encoded', 'venue_surface_encoded', 'year', 'day']\n",
        "\n",
        "X_new = data[Before_game_features]  # Assuming 'data' contains your dataset with all features\n",
        "\n",
        "# One-hot encode the target variable (result)\n",
        "y = data['result']\n",
        "y_new = to_categorical(y + 1, num_classes=3)  # Shift to make classes 0, 1, 2\n",
        "\n",
        "# Normalize the data using a new scaler\n",
        "new_scaler = StandardScaler()\n",
        "X_new = new_scaler.fit_transform(X_new)\n",
        "\n",
        "# Step 2: Apply PCA\n",
        "pca = PCA(n_components=5)  # Reduce to 10 components (adjust based on variance explained or model performance)\n",
        "X_pca = pca.fit_transform(X_new)\n",
        "\n",
        "# Step 3: Create a new model architecture\n",
        "input_shape = X_pca.shape[1]\n",
        "\n",
        "# Define the new model architecture\n",
        "new_model = Sequential()\n",
        "new_model.add(Dense(128, activation='relu', input_shape=(input_shape,)))\n",
        "new_model.add(Dropout(0.3))  # Add dropout to prevent overfitting\n",
        "new_model.add(Dense(64, activation='relu'))\n",
        "new_model.add(Dropout(0.3))\n",
        "new_model.add(Dense(32, activation='relu'))\n",
        "new_model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Step 4: Transfer learning\n",
        "# Load weights from the base model except for the first layer\n",
        "# Transfer learning: Load weights from the base model, skipping layers where the shapes don't match\n",
        "for i in range(1, min(len(new_model.layers), len(model.layers))):  # Ensure matching layer indices\n",
        "    try:\n",
        "        if new_model.layers[i].get_weights()[0].shape == model.layers[i].get_weights()[0].shape:\n",
        "            new_model.layers[i].set_weights(model.layers[i].get_weights())\n",
        "        else:\n",
        "            print(f\"Skipping weight transfer for layer {i} due to shape mismatch.\")\n",
        "    except IndexError:\n",
        "        print(f\"Skipping weight transfer for layer {i} due to index error.\")"
      ],
      "metadata": {
        "id": "YLZWA3RkM7IA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77e642d-3fd7-409c-a4b5-883ec9e6b073"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping weight transfer for layer 1 due to index error.\n",
            "Skipping weight transfer for layer 2 due to shape mismatch.\n",
            "Skipping weight transfer for layer 3 due to index error.\n",
            "Skipping weight transfer for layer 4 due to shape mismatch.\n",
            "Skipping weight transfer for layer 5 due to index error.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Compile and Train the New Model\n",
        "new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on your new dataset (use the appropriate labels for this dataset)\n",
        "new_model.fit(X_pca, y_new, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the new model\n",
        "loss, accuracy = new_model.evaluate(X_pca, y_new)\n",
        "print(f'New Model Accuracy after PCA: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "cozMCJ66M7Fy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b06ac9-5338-4f4b-819e-4f6ecbdf0cd8"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5402 - loss: 0.8434 - val_accuracy: 0.5334 - val_loss: 0.7327\n",
            "Epoch 2/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5427 - loss: 0.7069 - val_accuracy: 0.5301 - val_loss: 0.7580\n",
            "Epoch 3/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5470 - loss: 0.7006 - val_accuracy: 0.5351 - val_loss: 0.7564\n",
            "Epoch 4/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5714 - loss: 0.6940 - val_accuracy: 0.5310 - val_loss: 0.7440\n",
            "Epoch 5/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5578 - loss: 0.6987 - val_accuracy: 0.5376 - val_loss: 0.7651\n",
            "Epoch 6/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5755 - loss: 0.6852 - val_accuracy: 0.4963 - val_loss: 0.7422\n",
            "Epoch 7/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5630 - loss: 0.6934 - val_accuracy: 0.5178 - val_loss: 0.7441\n",
            "Epoch 8/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5805 - loss: 0.6878 - val_accuracy: 0.5301 - val_loss: 0.7456\n",
            "Epoch 9/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5759 - loss: 0.6956 - val_accuracy: 0.5244 - val_loss: 0.7624\n",
            "Epoch 10/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5727 - loss: 0.6962 - val_accuracy: 0.5202 - val_loss: 0.7607\n",
            "Epoch 11/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5668 - loss: 0.6907 - val_accuracy: 0.5343 - val_loss: 0.7740\n",
            "Epoch 12/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5746 - loss: 0.6971 - val_accuracy: 0.5136 - val_loss: 0.7482\n",
            "Epoch 13/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5652 - loss: 0.7002 - val_accuracy: 0.5301 - val_loss: 0.7537\n",
            "Epoch 14/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5856 - loss: 0.6844 - val_accuracy: 0.5334 - val_loss: 0.7597\n",
            "Epoch 15/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5744 - loss: 0.6888 - val_accuracy: 0.5153 - val_loss: 0.7531\n",
            "Epoch 16/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5790 - loss: 0.6879 - val_accuracy: 0.5392 - val_loss: 0.7761\n",
            "Epoch 17/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5726 - loss: 0.6919 - val_accuracy: 0.5318 - val_loss: 0.7671\n",
            "Epoch 18/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5746 - loss: 0.6872 - val_accuracy: 0.5351 - val_loss: 0.7620\n",
            "Epoch 19/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5622 - loss: 0.6925 - val_accuracy: 0.5277 - val_loss: 0.7600\n",
            "Epoch 20/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5800 - loss: 0.6873 - val_accuracy: 0.5285 - val_loss: 0.7688\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5720 - loss: 0.6886\n",
            "New Model Accuracy after PCA: 0.57\n"
          ]
        }
      ]
    }
  ]
}